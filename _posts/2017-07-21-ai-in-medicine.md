---
layout: post
title: "AI in Medicine"
date: 2017-07-21
---

Notes from the "AI in Medicine" conference talk at the Department of Biomedical Informatics, Harvard Medical School. 

1. Be suspicious about hype
    1. Zak already went through a big hype cycle in medicine
        1. From his own advisors 30 years ago: (a) doctors are obselete, (b) computers will solve all problems, (c) We’ll get much better care
        2. Basically none of these have come to fruition.
    2. Even in 1970: hype in NEJM: “medicine and the computer”
    3. There WILL be an AI winter. People start funding things they don’t understand, and business plans go up in smoke. 
2. Big money questions
    1. Will AI be primary tool for billing info warfare?
    2. Game over for medical imaging? How does work/$$$ be redistributed? 
    3. Bypass existing healthcare processes? 
    4. Better outcomes?
3. Potential and Problems
    1. Healthcare receives heavy investment because it is seen as untransformed, i.e. low-hanging fruit. 
    2. One example: reducing medical errors, which cost 20-30 billion USD/year. 
    3. Problems: 
        1. Incentives not there- hospitals don’t share cost.
        2. Business model of decision support implies paying better for better quality, but NO INCENTIVES
        3. Patients are not considered (payers, providers, pharma)
4. Examples
    1. Failure example: IBM/Watson
    2. Success example? Google + diabetic retinopathy
        1. This tech actually helps doctors (does not replace them). 
        2. They make money from operating. Makes the less lucrative part (image analysis) easier.
    3. Another success example: Dermatologist classification of skin cancers
        1. More referrals for biopsies
        2. Less specific and more sensitive => biopsies ++
        3. Risk: adversarial examples can force results by adjusting weights inperceptibly.
        4. FDA will never approve a predictive system right now. The best in the near future is augmented information about lesions to pass to providers => preference for assessment score / enhanced features.
        5. Insurance companies will set the assessment score cutoff.
5. Bringing it into practice
    1. Utilization review criteria (FDA approval is not needed to assess doctors, and this can still influence care). 
    2. Pushing point of responsibility from doctor to insurance/hospital decisions. 
    3. Patient decision: choosing AI vs. MD
6. Role of Physicians
    1. Physicians are critical to help AI earn acceptance. 
    2. AI can help physicians get rid of repetitive/draining tasks. The easy cases are most of the cases. Doctors don’t want to see the screen if everything is normal. 
    3. Doctors are pretty good general decision-makers. AI are better at specifics.
    4. If you ask doctors about drug dosage defaults, they’ll debate forever. If you just set the default, they go with it. 
    5. Health system dynamics: data is often reflective of system effects. Need physicians to parse this. 
7. Role of industry
    1. Provide data and funding. Manage IP transfer. 
    2. If industry and all are interested in replacing physicians, the goal is too ambitious. Will only hasten the AI winter. 
8. Data => EHR => Dx, Rx, prognosis
    1. Path 1: Data => AI => EHR (helps doctor make decision)
        1. EHR companies love this
    2. Path 2: Data => AI => DIRECTLY to patient. 
        1. Ex: Atul Butte’s Personalis goes D2C, circumvents the EHR. 







