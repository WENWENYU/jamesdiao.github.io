---
title: "Scraping Data III"
author: "STAT 230"
date: "3/9/2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Scraping Wikipedia

```{r}
library(XML)
url <- "https://en.wikipedia.org/wiki/United_States_presidential_election,_2016"
```

Because Wikipedia (as of October 2016) uses **https**, we cannot just go ahead and run `readHTMLTable()` directly on this url. Instead, we need an extra step.


```{r}
x <- readLines(url)
x <- readHTMLTable(x, stringsAsFactors=FALSE)

length(x)

for (i in 1:length(x)) {
  cat("i : ", i, " | dim: ", dim(x[[i]]), "\n")
}

head(x[[32]])
x <- x[[32]]
```

Cleaning up of this data frame:

```{r}
x <- x[, c(1:11)]
head(x)

colnames(x) <- c("state", "method", "clinton_ct", 
                 "clinton_pct", "clinton_elec",
                 "trump_ct", 
                 "trump_pct", "trump_elec",
                 "johnson_ct", 
                 "johnson_pct", "johnson_elec")

x <- x[-1,]
head(x)
```

Let's convert the `_ct` columns into numbers.

```{r}
cols <- grep("_ct", colnames(x))
cols

for (i in cols) {
  x[,i] <- gsub(",", "", x[,i])
  x[,i] <- as.numeric(x[,i])
}
```

`_pct` column cleaning:

```{r}
cols <- grep("_pct", colnames(x))
cols

for (i in cols) {
  x[,i] <- gsub("%", "", x[,i])
  x[,i] <- as.numeric(x[,i])
}
```

`_elec` column cleaning:

```{r}
cols <- grep("_elec", colnames(x))
cols

for (i in cols) {
  x[,i] <- as.numeric(x[,i])
  x[is.na(x[,i]), i] <- 0
}
head(x)
```


Suppose we're also interested in merging in other bits of state-by-state information to help explain the outcome of the election. We could do this by searching up on Google something like

> wikipedia list of states by X






Educational attainment:

```{r}
url <- "https://en.wikipedia.org/wiki/List_of_U.S._states_by_educational_attainment"

y <- readLines(url)
y <- readHTMLTable(y, stringsAsFactors=FALSE)
y <- y[[2]]
```

Cleaning up the percent signs:

```{r}
cols <- grep("%", colnames(y))
cols

for (i in cols) {
  y[,i] <- gsub("%", "", y[,i])
  y[,i] <- as.numeric(y[,i])
}
head(y)


```

Remove the ranks:

```{r}
cols <- grep("Rank", colnames(y))
cols
y <- y[, -cols]
head(y)
```

Fix up the column names:

```{r}
colnames(y) <- c("state", "hs_pct", "ba_pct", "adv_pct")
```


Some quick plots:

```{r}
plot(ba_pct ~ hs_pct, data=y, type="n")
text(y$hs_pct, y$ba_pct, y$state )
```


Merge this with our other dataset.

```{r}
z <- merge(x, y, by="state")
dim(z)
dim(y)
dim(x)
```


Plot of election outcomes vs. education:

```{r}
z$diff <- z$clinton_pct - z$trump_pct
hist(z$diff)

plot(diff ~ hs_pct, data=z)
plot(diff ~ ba_pct, data=z)

z$state[z$ba_pct > 50]
z$state[9]

dc <- (z$ba_pct > 50)*1
dc

m1 <- lm(diff ~ ba_pct, data=z)
summary(m1)

m2 <- lm(diff ~ ba_pct, data=z[dc == 0,])
summary(m2)
```

`choroplethr` is a package for plotting things on a map.

```{r}
#install.packages("choroplethr")
library(choroplethr)
```


```{r}
data(df_pop_state)
state_choropleth(df_pop_state, 
                 title  = "US 2012 State Population Estimates", 
                 legend = "Population")
```

```{r}
mydf <- df_pop_state
mydf[,2] <- NA

mystates <- tolower(z[,1])
mystates <- mystates[dc == 0]

resid_df <- data.frame(mystates, resid(m2))

mydf <- merge(mydf, resid_df, by.x="region", by.y = "mystates")
head(mydf)

mydf <- mydf[,-2]
colnames(mydf)[2] <- "value"


state_choropleth(mydf, 
                 title  = "Residuals (US Election Outcomes After Accounting for % BA)", 
                 legend = "Residuals")
```

